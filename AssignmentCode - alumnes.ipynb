{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes i Classificació\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest tercer lliurament es programarà un classificador, que donat un tweet el categoritzarà en una de les possibles classes. En aquesta ocasió, implementareu un classificador amb tweets de polítics.\n",
    "\n",
    "\n",
    "**Què s’ha de fer?**\n",
    "\n",
    "Volem classificar tweets corresponents a diferents politics segons a quin partit polític pertanyen. \n",
    "A partir de tots els tweets que tenim, crearem un vector de característiques que ens descrigui cada un dels tweets. \n",
    "Finalment desenvoluparem un classificador probabilístic del tipus Naive Bayes que ens permeti identificar a quin partit polític pertany un tweet donat segons les característiques triades.\n",
    "\n",
    "\n",
    "**Quina és la idea del sistema de classificació que s’ha de desenvolupar?**\n",
    "\n",
    "El classificador és un concepte de l'aprenentatge automàtic supervisat. \n",
    "L'objectiu del classificador és donat un vector de característiques que descriuen els objectes que es volen classificar indicar a quina categoria o classe pertanyen d'entre un conjunt predeterminat. \n",
    "El procés de classificació consta de dues parts: \n",
    "(a) el procés d'aprenentatge i \n",
    "(b) el procés d'explotació o testeig. \n",
    "El procés d'aprenentatge rep exemples de parelles $(x,y)$ on $x$ són les característiques, usualment nombres reals, i $y$ és la categoria a la que pertanyen. \n",
    "Aquest conjunt se'l coneix com a conjunt d'entrenament i ens servirà per trobar una funció $\\hat{y}=h(x)$ que donada una $x$ aconsegueixi que $\\hat{y}=y$. Per altra banda el procés de testeig aplica la funció $h(x)$ apresa a l'entrenament a una nova descripció per veure quina categoria li correspon.\n",
    "\n",
    "\n",
    "**Classificació i llenguatge natural**\n",
    "\n",
    "La descripció dels exemples en característiques és el punt més crític de tot sistema d'aprenentatge automàtic. \n",
    "Una de les representacions més simples per tal de descriure un text és la representació *bag-of-words*.\n",
    "Aquesta representació converteix un text en un vector de $N$ paraules. \n",
    "Consisteix en seleccionar un conjunt d'$N$ paraules i per cada paraula comptar quants cops apareix en el text. \n",
    "Una versió alternativa d'aquest procés pot ser simplement indicar si apareix o no en el text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abans de començar\n",
    "\n",
    "\n",
    "**\\+ Durant la pràctica, solament es podran fer servir les següents llibreries**:\n",
    "\n",
    "`Pandas, Numpy` i `NLTK`\n",
    "\n",
    "*Nota: A més de les que ja es troben presents en la 1a cel·la i funcions natives de Python*\n",
    "\n",
    "**\\+ No es poden modificar les definicions de les funcions donades, ni canviar els noms de les variables i paràmetres ja donats**\n",
    "\n",
    "Això no implica però que els hàgiu de fer servir. És a dir, que la funció tingui un paràmetre anomenat `df` no implica que l'hàgiu de fer servir, si no ho trobeu convenient.\n",
    "\n",
    "**\\+ En les funcions, s'especifica què serà i de quin tipus cada un dels paràmetres, cal respectar-ho**\n",
    "\n",
    "Per exemple (ho posarà en el pydoc de la funció), `df` sempre serà indicatiu del `Pandas.DataFrame` de les dades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pickle\n",
    "from os.path import join as path, dirname\n",
    "\n",
    "try:\n",
    "    from IPython.core.display import HTML\n",
    "\n",
    "    def pprint(df):\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(HTML(pd.DataFrame(df).to_html()))\n",
    "except:\n",
    "    def pprint(df):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data')\n",
    "df_tweets_train = pd.read_excel(path('data', 'train.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_train.head())\n",
    "print(df_tweets_train.shape)\n",
    "\n",
    "print('Test data')\n",
    "df_tweets_test = pd.read_excel(path('data', 'test.xlsx'), index_col='Id')\n",
    "pprint(df_tweets_test.head())\n",
    "print(df_tweets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementació\n",
    "\n",
    "Dividirem el notebook en 3 seccions que es complementen una a l'altra:\n",
    "\n",
    "1. Anàlisis de dades: Informació bàsica sobre els tweets\n",
    "2. Processament de les dades: Creació d'un vector de característiques a partir dels tweets\n",
    "3. Classificació amb Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisis de dades\n",
    "\n",
    "El primer que haurem de fer és analitzar les dades mitjançant diferents funcions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(df):\n",
    "    \"\"\"\n",
    "    Retorna el número de tweets en el dataframe\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :return : número de tweets\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna els usuaris dels polítics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Llista de strings amb els nom dels usuaris\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def count_politicians(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de polítics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def get_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna els partits polítics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Llista de strings amb els nom dels partits polítics que han tuitejat\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def count_political_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de partits polítics que han tuitejat\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : Enter amb la quanitat d'usuaris que han tuitejat\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def count_tweet_politician(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per polític\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : pd.Series amb la quantitat de tweets per polític\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def count_tweet_party(df):\n",
    "    \"\"\"\n",
    "    Retorna la quantitat de tweets per partit polític\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :return : pd.Series amb la quantitat de tweets per partit polític\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def top_retweet(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets que han sigut més retuitejats\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :params n: número de tweets per veure\n",
    "    :return : pd.Series amb els top retweets\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def top_favorite(df, n):\n",
    "    \"\"\"\n",
    "    Retorna els n tweets més favorits\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :params n: número de tweets per veure\n",
    "    :return : pd.Series amb els top favorits\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_tweets(df_tweets_train))\n",
    "print(get_politicians(df_tweets_train), count_politicians(df_tweets_train))\n",
    "print(get_political_party(df_tweets_train), count_political_party(df_tweets_train))\n",
    "\n",
    "count_tweet_politician(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "count_tweet_party(df_tweets_train).plot.bar()\n",
    "plt.show()\n",
    "\n",
    "pprint(top_retweet(df_tweets_train, 5))\n",
    "pprint(top_favorite(df_tweets_train, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptar paraules\n",
    "\n",
    "El primer que haurem d'implementar és la funció *normalize* que normalitzarà les paraules.\n",
    "\n",
    "No modificar la següent cel·la, s'encarrega de guardar una caché de la funció normalize per accelerar el procés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    class memodict(dict):\n",
    "        def __init__(self, f):\n",
    "            self.f = f\n",
    "        def __call__(self, *args):\n",
    "            return self[args]\n",
    "        def __missing__(self, key):\n",
    "            ret = self[key] = self.f(*key)\n",
    "            return ret\n",
    "        \n",
    "    return memodict(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def normalize(word):\n",
    "    \"\"\"\n",
    "    Funció que donada una paraula la normalitzi\n",
    "    Exemple: inFO*RmÀ745tica? ---> informatica\n",
    "    \n",
    "    :param word: paraula a normalitzar\n",
    "    :return : paraula normalitzada\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "normalize('inFO*RmÀ745tica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_words(sentence):\n",
    "    \"\"\"\n",
    "    Funció que donada una frase, generi una llista amb totes les seves paraules normalitzades.\n",
    "    \n",
    "    :param sentence: frase a transformar\n",
    "    :return : llista de paraules (no buides) normalitzades\n",
    "    \n",
    "    Exemple: **Taller DELS noUS U**SOS    de la inFO#Rm765Àtica? ---> \n",
    "        ['taller', 'dels', 'nous', 'usos', 'de', 'la', 'informatica']\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "sentence_to_words('**Taller DELS noUS U**SOS    de la inFO#Rm765Àtica?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    \"\"\"\n",
    "    Funció que ha de construir un DataFrame amb índex les paraules normalitzades,\n",
    "    i columnes n_ocur (nombre de vegades que apareix la paraula a tots els tweets)\n",
    "    i n_tweets (nombre de tweets on apareix la paraula alguna vegada).\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :return : DataFrame especificat.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_words(df_tweets_train)\n",
    "    \n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar paraules per partit polític"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_parties(df):\n",
    "    \"\"\"\n",
    "    Funció que ha de construir un DataFrame amb columnes les paraules normalitzades,\n",
    "    i índex cadascún dels partits, contenint el nombre de vegades que cada paraula\n",
    "    ha aparegut a tweets del partit.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :return : DataFrame esmentat.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "words_parties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paraules més freqüents als tweets\n",
    "\n",
    "\n",
    "**El problema de com escollir el vector de carecterístiques**\n",
    "\n",
    "L'elecció de les paraules que formen el vector de característiques és un pas crític. \n",
    "En funció de com de bona sigui aquesta descripció, millor funcionarà el sistema. \n",
    "Tot i que us deixem a vosaltres la política de creació del vector de característiques us donem una d'exemple. \n",
    "Per saber quines paraules fer servir una possible estratègia és agafar aquelles paraules que apareixen entre en un 10 i un 50 percent del total (sense tenir en compte el partit). \n",
    "Podeu experimentar variant aquests valors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_words = [] # depèn de vosaltres emplenar aquesta llista amb possibles paraules a excloure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNwords(df, words, N, skip=[]):\n",
    "    \"\"\"\n",
    "    Funció que crea un pd.Series amb índex cadascún dels partits,\n",
    "    i values una llista de les N paraules més representatives \n",
    "    (les que apareixen amb més freqüència) de cadascún dels partits polítics.\n",
    "    \n",
    "    :param df: DataFrame amb els tweets i la informació associada\n",
    "    :param words: diccionari amb les paraules i la seva frequencia\n",
    "    :param N: número de paraules més representatives que volem considerar\n",
    "    :return : pd.Series resultant.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "\n",
    "top_words = topNwords(df_tweets_train, words_parties, 10, skip_words)\n",
    "\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De cara a millores, tingueu en compte que també haureu de filtrar aquelles paraules que apareixen en la majoria  de tweets, així com també, les que únicament apareixen en un conjunt molt petit de tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector de Característiques\n",
    "Creeu el vector de característiques necessari per a fer l’entrenament del Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, top_words): \n",
    "    \"\"\"\n",
    "    Funció que crea un vector de característiques necessari per a l'entrenament del classificador Naive Bayes.\n",
    "    Retorna un DataFrame on cada fila representa el vector de característiques del corresponent tweet.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada\n",
    "    :params top_words: ha de ser el pd.Series que retorna topNWords\n",
    "    :return : pd.DataFrame resultant.\n",
    "    \"\"\"\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # Aquest parametre el podem canviar i fer proves per avaluar quin és el millor valor.\n",
    "\n",
    "words_parties = count_words_parties(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_parties, N, skip_words)\n",
    "features = create_features(df_tweets_train, top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El classificador Naïve Bayes\n",
    "\n",
    "Un cop tenim una representació necessitem un procés d'aprenentatge que ens permeti passar de la descripció a una categoria. \n",
    "En aquest lliurament farem servir el classificador Naïve Bayes. \n",
    "Aquest classificador forma part de la família de classificadors probabilístics. \n",
    "La sortida d'un classificador probabilístic és un valor de probabilitat donat un exemple per cadascuna de les categories. \n",
    "La decisió final correspon a la categoria amb més probabilitat. \n",
    "\n",
    "\n",
    "Els classificadors probabilistics Bayesians es basen en el teorema de Bayes per realitzar els càlculs per trobar la probabilitat condicionada: \n",
    "$$ p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "d'on podem extreure que: \n",
    "$$ p(y|x) = \\frac{p(x|y)p(y)}{p(x)}$$\n",
    "\n",
    "\n",
    "En molts casos $p(y)$ i $p(x)$ són desconeguts i es consideren equiprobables. \n",
    "Per tant, la decisió es simplifica a:\n",
    "$$ p(y|x) = c · p(x|y)$$\n",
    "\n",
    "\n",
    "Les deduccions fins a aquest punt són vàlides per la majoria de classificadors Bayesians. \n",
    "Naïve Bayes es distingeix de la resta perquè imposa una condició encara més restrictiva. \n",
    "Considerem $x=(x_1, \\cdots, x_n)$ un conjunt d'$N$ variables aleatòries. \n",
    "Naïve Bayes assumeix que totes elles són independents entre elles i per tant podem escriure:\n",
    "$$p(x_1,x_2,...,x_N | y) = p(x_1|y)p(x_2|y)...p(x_N|y)$$\n",
    "\n",
    "\n",
    "Podem interpretar l'anterior equació de la següent forma: La probabilitat de que el tweet descrit pel vector de característiques (0,1,0,1,1,1) sigui de la classe \"comuns\" és proporcional al producte de la probabilitat que la primera paraula del vector no aparegui en els tweets sobre \"comuns\"  per la probabilitat que la segona paraula sí que hi aparegui, etc.\n",
    "\n",
    "\n",
    "**Estimant les probabilitats marginals condicionades**\n",
    "\n",
    "L'últim pas que ens queda és trobar el valor de les probabilitats condicionades. \n",
    "Farem servir la representació de $0$'s i $1$'s indicant que la paraula no apareix (0) o sí apareix (1) a al tweet. \n",
    "Per trobar el valor de la probabilitat condicionada farem servir una aproximació freqüentista a la probabilitat. \n",
    "Això vol dir que calcularem la freqüència d'aparició de cada paraula per a cada categoria. \n",
    "Aquest càlcul es fa dividint el nombre de tweets de la categoria en que apareix la paraula pel nombre total de tweets d'aquella categoria. \n",
    "\n",
    "En general:\n",
    "$$p(x = \\text{\"badalona\"} | y = C)= \\frac{A}{B} $$\n",
    "on A és el número de tweets de la categoria C on hi apareix la paraula 'badalona' i B és el número total de tweets de la categoria C.\n",
    "\n",
    "\n",
    "### Punts dèbils:\n",
    "\n",
    "**El problema de la probabilitat 0**\n",
    "\n",
    "Si us hi fixeu bé, la probabilitat pot ser 0 !! \n",
    "Això vol dir, que si en el tweet no hi apareix una paraula no pot ser classificada com un partit polític.\n",
    "No sembla raonable que s'assigni o no en aquesta categoria segons si en el tweet hi apareix o no una única paraula. \n",
    "Per tant, el que s'acostuma a fer és donar una baixa probabilitat en comptes de zero. \n",
    "Una de les possibles solucions es fer servir la correcció de Laplace. \n",
    "Seguint l'exemple anterior la correcció de Laplace és\n",
    "$$p(x= \\text{\"badalona\"} | y = 'C' ) = \\frac{A+1}{B+M}$$ \n",
    "on M és el nombre de categories\n",
    "\n",
    "**El problema del \"underflow\"**\n",
    "\n",
    "La funció que hem de calcular en el Naive Bayes és un producte. \n",
    "El nombre de caractéristiques del vector és el nombre de termes del producte. \n",
    "Aquests nombres són iguals o menors a 1, si els multipliquem tots entre ells el resultat serà massa petit per a representar-lo en un nombre de punt flotant i el càlcul acabarà sent reduït a zero. \n",
    "Per solucionar aquest problema en comptes d'operar fent multiplicacions, se sol passar a l'escala logarítmica i allà operar fent servir sumes en comptes de multiplicacions.\n",
    "\n",
    "### Classificar:\n",
    "\n",
    "Donat un vector de característiques $x=(x_1,...,x_n)$, per classificar el que farem serà calcular la probabilitat de pertànyer a cada un dels partits polítics:\n",
    "\n",
    "$$p(\\text{comuns}|x) = p(\\text{comuns})\\prod_{i=1}^np(x_i|\\text{comuns})$$\n",
    "$$\\cdots$$\n",
    "$$p(\\text{psc}|x) = p(\\text{psc})\\prod_{i=1}^np(x_i|\\text{psc})$$\n",
    "\n",
    "I finalment, el tweet és del partit de probabilitat màxima. Tingues en compte que per $x_i = 0$ s'ha de considerar la probabilitat inversa, és a dir, la probabilitat de ser de la clase $C$ quan $x_i = 0$ ve donada per $1 - p(x_i|C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementeu la funció d'aprenentatge del classificador Naïve Bayes (funció **naive_bayes_learn()**). La funció ha de mostrar per pantalla el resultat obtingut \n",
    "L'**error d'entrenament** es troba calculant el percentatge d'errors que s'obtenen quan es fa el testeig amb les mateixes dades utilizades per fer entrenament (aprenentatge). Aquest error es un valor molt optimista de com funcionarà el clasificador i mai s'ha de prendre com a mesura per comparar clasificadors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_learn(df, feats):\n",
    "    \"\"\"\n",
    "    Funció que estima les probabilitats marginals condicionades.\n",
    "    \n",
    "    :params df: DataFrame amb els tweets i la informació associada (atribut party)\n",
    "    :params feats: DataFrame de features de cada tweet.\n",
    "    :return : DataFrame amb les probabilitats marginals condicionades amb la correcció de Laplace,\n",
    "        on files són les feature words, i columnes són els partits.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, split):\n",
    "    \"\"\"\n",
    "    Funció que separa les dades en training i test\n",
    "    \n",
    "    :param df:\n",
    "    :param split: proporció de les dades que seràn per l'entrenament\n",
    "    :return : retorna dos dataframes corresponents a l'entrenament i al test\n",
    "    \"\"\"\n",
    "    assert split <= 1, 'split must be between 0 and 1'\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(df_train, feat_train, feat_test, df_test=None):\n",
    "    \"\"\"\n",
    "    Funció que implementa el clasificador Naive_Bayes, és a dir entrena amb les\n",
    "    característiques d'entrenament i després utilitza les probabilitats estimades\n",
    "    per classificar els vectors de test, segons la fórmula\n",
    "    p(C_j|x) = p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)\n",
    "    i agafant la màxima.\n",
    "    \n",
    "    Tingues en compte el problema de l'underflow:\n",
    "    log(p(C_j|x)) = log(p(C_j) * p(x_1|C_j) * ... * p(x_n|C_j)) =\n",
    "                  = log(P(C_j)) + log(p(x_1|C_j)) + ... + log(p(x_n|C_j))\n",
    "                  \n",
    "    I recorda, per x_i = 0 cal considerar 1 - p(x_1|C_j).\n",
    "    \n",
    "    Si df_test no és None, ha de calcular l'encert sobre les dades de test. És a dir,\n",
    "    després de classificar feat_test ha de comparar la classificació amb la classe\n",
    "    real i dir (print) quin percentatge d'encert ha obtingut.\n",
    "    \n",
    "    :param df_train: DataFrame amb els tweets que s'utilitzaran per l'entrenament\n",
    "    :param feat_train: Diccionari amb els vectors de caracteristiques de cada tweet de l'entrenament\n",
    "    :param feat_test: Diccionari amb els vectors de caracteristiques de cada tweet de test\n",
    "    :param df_test: En cas d'estar disponible (per Kaggle no hi és), \n",
    "        DataFrame amb els tweets que s'utilitzaran pel test\n",
    "    \n",
    "    :return : Una serie on l'index correspon amb els indexos de df_test i els valors són la\n",
    "        classificació retornada per Naive Bayes\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = split_train_test(df_tweets_train, 0.8)\n",
    "\n",
    "N = 20 # Aquest parametre el podem canviar i fer proves per avaluar quin és el millor valor. \n",
    "words_topics = count_words_parties(df_train)\n",
    "top_words = topNwords(df_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_train, top_words)\n",
    "feat_test = create_features(df_test, top_words)\n",
    "\n",
    "preds = naive_bayes(df_train, feat_train, feat_test, df_test)\n",
    "    \n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/t/ef3079700f9e49609ff7a2e70c6fc97e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_topics = count_words_parties(df_tweets_train)\n",
    "top_words = topNwords(df_tweets_train, words_topics, N, skip_words)\n",
    "\n",
    "feat_train = create_features(df_tweets_train, top_words)\n",
    "feat_test = create_features(df_tweets_test, top_words)\n",
    "\n",
    "result = naive_bayes(df_tweets_train, feat_train, feat_test)\n",
    "result.index.name = 'tweet_id'\n",
    "result.name = 'party'\n",
    "result.to_frame().to_csv('submission.csv')\n",
    "pprint(result.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
